{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyONE4OYDwKMoLGIzIHEameY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"FDIWoHxGLfwM","executionInfo":{"status":"ok","timestamp":1666718904239,"user_tz":-180,"elapsed":426,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from pytorch_pretrained_bert import BertTokenizer, BertModel"]},{"cell_type":"code","source":["!pip install pytorch_pretrained_bert"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mRX6G6LaL0V9","executionInfo":{"status":"ok","timestamp":1666718893306,"user_tz":-180,"elapsed":10713,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}},"outputId":"83b96a07-dad1-4dd3-88c0-cc46ad7c9e37"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch_pretrained_bert\n","  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n","\u001b[K     |████████████████████████████████| 123 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.12.1+cu113)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2022.6.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.64.1)\n","Collecting boto3\n","  Downloading boto3-1.25.0-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 40.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.1.1)\n","Collecting botocore<1.29.0,>=1.28.0\n","  Downloading botocore-1.28.0-py3-none-any.whl (9.3 MB)\n","\u001b[K     |████████████████████████████████| 9.3 MB 53.7 MB/s \n","\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n","  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 7.5 MB/s \n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 59.6 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.29.0,>=1.28.0->boto3->pytorch_pretrained_bert) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.29.0,>=1.28.0->boto3->pytorch_pretrained_bert) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2022.9.24)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 69.0 MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed boto3-1.25.0 botocore-1.28.0 jmespath-1.0.1 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.0 urllib3-1.25.11\n"]}]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n","phrase = 'He ran quickly after the red bus and caught it'\n","tokenized_phrase = tokenizer.tokenize(phrase)"],"metadata":{"id":"BfnDYyilMBfq","executionInfo":{"status":"ok","timestamp":1666719184545,"user_tz":-180,"elapsed":566,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["tokenized_phrase"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cktpt0h_MwGI","executionInfo":{"status":"ok","timestamp":1666719186802,"user_tz":-180,"elapsed":3,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}},"outputId":"f2dab4b2-a3ed-4721-cb10-bbb66331212f"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['he', 'ran', 'quickly', 'after', 'the', 'red', 'bus', 'and', 'caught', 'it']"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["bert_model = BertModel.from_pretrained('bert-base-multilingual-uncased').eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OSHGN8-YM3E7","executionInfo":{"status":"ok","timestamp":1666719258415,"user_tz":-180,"elapsed":31702,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}},"outputId":"88cb2754-59f0-4277-939d-725b4716f188"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 623743758/623743758 [00:18<00:00, 34612487.77B/s]\n"]}]},{"cell_type":"code","source":["tokenized_phrase = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(phrase))"],"metadata":{"id":"kAGXq-Z-NsR7","executionInfo":{"status":"ok","timestamp":1666719377672,"user_tz":-180,"elapsed":2,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["tokenized_phrase"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ckMe2jhwN3yt","executionInfo":{"status":"ok","timestamp":1666719394989,"user_tz":-180,"elapsed":265,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}},"outputId":"4f756e66-a4ec-450e-ab64-28e99d08d913"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[10191, 15695, 23559, 10515, 10103, 10452, 15952, 10110, 34576, 10197]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["with torch.no_grad():\n","    embeddings = bert_model(torch.tensor(tokenized_phrase).unsqueeze(0))\n"],"metadata":{"id":"wwfrIJyDNSvi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embeddings[0][0].size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ClYgqQ00OW7T","executionInfo":{"status":"ok","timestamp":1666719550519,"user_tz":-180,"elapsed":3,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}},"outputId":"49f7a40d-2318-489d-e2a2-c7de400e792b"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 10, 768])"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["classifier = nn.Linear(768, 20)\n","\n","predict = classifier(embeddings)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EsiGjkjyOkZA","executionInfo":{"status":"ok","timestamp":1666719574836,"user_tz":-180,"elapsed":2,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}},"outputId":"593f40ca-174c-4445-eff1-d60980ef20ea"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset\n","from torch.nn.utils.rnn import pad_sequence\n","\n","class DatasetSeq(Dataset):\n","    def __init__(self, data_dir, train_lang='en'):\n","\t#open file\n","        tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n","        bert_model = BertModel.from_pretrained('bert-base-multilingual-uncased').eval()\n","        with open(data_dir + train_lang + '.train', 'r') as f:\n","            train = f.read().split('\\n\\n')\n","\n","        # delete extra tag markup\n","        train = [x for x in train if not '_ ' in x]\n","\t    #init vocabs of tokens for encoding {<str> token: <int> id}\n","        self.target_vocab = {} # {p: 1, a: 2, r: 3, pu: 4}\n","        self.word_vocab = {} # {cat: 1, sat: 2, on: 3, mat: 4, '.': 5}\n","\t    \n","        # Cat sat on mat. -> [1, 2, 3, 4, 5]\n","        # p    a  r  p pu -> [1, 2, 3, 1, 4]\n","        # chars  -> [1, 2, 3, 4, 5, 2, 3, 4]\n","\n","\t    #init encoded sequences lists (processed data)\n","        self.embeddings = []\n","        self.encoded_targets = []\n","        # n=1 because first value is padding\n","        n_word = 1\n","        n_target = 1\n","        for line in train:\n","            sequence = []\n","            target = []\n","            for item in line.split('\\n'):\n","                if item != '':\n","                    word, label = item.split(' ')\n","\n","                    if self.word_vocab.get(word) is None:\n","                        self.word_vocab[word] = n_word\n","                        n_word += 1\n","                    if self.target_vocab.get(label) is None:\n","                        self.target_vocab[label] = n_target\n","                        n_target += 1\n","                    \n","                    sequence.append(self.word_vocab[word])\n","                    target.append(self.target_vocab[label])\n","            sequence = ' '.join(sequence)\n","            #TODO check tokens with ##\n","            tokens = tokenizer.tokenize(sequence)\n","            tokenized = tokenizer.convert_tokens_to_ids(tokens)\n","            with torch.no_grad():\n","                embeddings = bert_model(torch.tensor(tokenized_phrase).unsqueeze(0))\n","            \n","            self.embeddings.append(embeddings)\n","            self.encoded_targets.append(target)\n","\n","    def __len__(self):\n","        return len(self.encoded_sequences)\n","\n","    def __getitem__(self, index):\n","        return {\n","            'data': self.embeddings[index], # [1, 2, 3, 4, 6] len=5\n","            'target': self.encoded_targets[index], #  (1)\n","        }"],"metadata":{"id":"1ntczNqsP1ax"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def collate_fn(batch):\n","    data = []\n","    target = []\n","    for item in batch:\n","        data.append(item['data'])\n","        target.append(torch.as_tensor(item['target']))\n","    data = pad_sequence(data, batch_first=True, padding_value=0.)\n","    target = pad_sequence(target, batch_first=True, padding_value=0)\n","\n","    return {'data': data, 'target': target}"],"metadata":{"id":"O_uHitzrRuU7"},"execution_count":null,"outputs":[]}]}