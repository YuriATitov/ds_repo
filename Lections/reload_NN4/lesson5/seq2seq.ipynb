{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNXDOUt22BEW7XQ523UXsbm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"in0PyicHhZDG","executionInfo":{"status":"ok","timestamp":1666285764955,"user_tz":-180,"elapsed":2239,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"outputs":[],"source":["import datetime\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"73ieMA485Tme","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666285792763,"user_tz":-180,"elapsed":27812,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}},"outputId":"c48f7317-e057-44f5-ba6f-f32e22abe160"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["fn = 'drive/My Drive/dataset_text.txt'\n"],"metadata":{"id":"Os4tVkvmkTIp","executionInfo":{"status":"ok","timestamp":1666285792763,"user_tz":-180,"elapsed":4,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset\n","from torch.nn.utils.rnn import pad_sequence\n","\n","\n","class DatasetSeq2Seq(Dataset):\n","    def __init__(self, file_name, train_lang='en', bos: str = '~', eos: str = '#'):\n","\n","        with open(file_name, 'r') as f:\n","            train = f.readlines()\n","\n","        self.input_sequnces_vocab = {'pad': 0, bos: 1, eos: 2}\n","        self.output_sequnces_vocab = {'pad': 0, bos: 1, eos: 2}\n","\n","        self.input_sequnces = []\n","        self.output_sequnces = []\n","\n","        n_input = 3\n","        n_output = 3\n","        for line in train:\n","            split_line = line.split('\\t')\n","\n","            sequence = [self.input_sequnces_vocab[bos]]\n","\n","            for char in split_line[0].strip():\n","                if self.input_sequnces_vocab.get(char) is None:\n","                    self.input_sequnces_vocab[char] = n_input\n","                    n_input += 1\n","                sequence.append(self.input_sequnces_vocab[char])\n","            sequence.append(self.input_sequnces_vocab[eos])\n","\n","            target = [self.output_sequnces_vocab[bos]]\n","            for char in split_line[2].strip():\n","                if self.output_sequnces_vocab.get(char) is None:\n","                    self.output_sequnces_vocab[char] = n_output\n","                    n_output += 1\n","                target.append(self.output_sequnces_vocab[char])\n","            target.append(self.output_sequnces_vocab[eos])\n","\n","            self.input_sequnces.append(sequence)\n","            self.output_sequnces.append(target)\n","\n","        self.target_decode = [k for k in self.output_sequnces_vocab.keys()]\n","\n","    def __len__(self):\n","        return len(self.input_sequnces)\n","\n","    def __getitem__(self, index):\n","        return {\n","            'data': self.input_sequnces[index],\n","            'target': self.output_sequnces[index],\n","        }\n","\n","\n","def collate_fn(input_data):\n","    data = []\n","    targets = []\n","\n","    for item in input_data:\n","        data.append(torch.as_tensor(item['data']))\n","        targets.append(torch.as_tensor(item['target']))\n","\n","    data = pad_sequence(data, batch_first=True, padding_value=0)\n","    targets = pad_sequence(targets, batch_first=True, padding_value=0)\n","    data_mask = data > 0\n","    targets_mask = targets > 0\n","\n","    return {'data': data, \n","            'target': targets, \n","            'data_mask': data_mask, \n","            'targets_mask': targets_mask,\n","            }"],"metadata":{"id":"SI8UCZuy7hTK","executionInfo":{"status":"ok","timestamp":1666285792764,"user_tz":-180,"elapsed":4,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["dataset = DatasetSeq2Seq(fn)"],"metadata":{"id":"dhJuBtoz7f43","executionInfo":{"status":"ok","timestamp":1666285794745,"user_tz":-180,"elapsed":1985,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#padding\n","# seq1 = [1, 2, 3, 4]\n","# seq2 = [9, 7, 6, 4, 3, 7, 5]\n","# pad seq1 equal seq2\n","# seq1 = [1, 2, 3, 4, 0, 0, 0]\n","# concat(seq1, seq2) [[1, 2, 3, 4, 0, 0, 0],\n","#                     [9, 7, 6, 4, 3, 7, 5]]"],"metadata":{"id":"0zXXXYP37gFL","executionInfo":{"status":"ok","timestamp":1666285794746,"user_tz":-180,"elapsed":9,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__(self, vocab_len, emb_dim, hidden_dim):\n","        super().__init__()\n","        self.emb = nn.Embedding(vocab_len, emb_dim)\n","        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n","\n","    def forward(self, x):\n","        emb = self.emb(x)\n","        _, context = self.rnn(emb)\n","\n","        return context\n","\n","class Decoder(nn.Module):\n","    def __init__(self, vocab_len, emb_dim, hidden_dim, eos_id):\n","        super().__init__()\n","        self.emb = nn.Embedding(vocab_len, emb_dim)\n","        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n","        self.classifier = nn.Linear(hidden_dim, vocab_len)\n","        self.do = nn.Dropout(0.1)\n","        self.eos = eos_id\n","\n","    def forward(self, context, target_sequence):\n","        if self.training:\n","            emb = self.emb(target_sequence)\n","            all_hid, _ = self.rnn(emb, context)\n","            pred_cls = self.classifier(self.do(all_hid))\n","\n","            return pred_cls\n","        else:\n","            predicts = []\n","            probas = []\n","            predicted_token = target_sequence #on this step target sequence contains bos only\n","            i = 0\n","            while predicted_token.item() != self.eos and i < 20:\n","                emb = self.emb(predicted_token)\n","                context, _ = self.rnn(emb, context) # context B x 1 x Hid\n","                pred = self.classifier(context)\n","                predicted_token = torch.argmax(pred, dim=-1) # B x 1\n","                predicts.append(predicted_token)\n","                probas.append(torch.softmax(pred, dim=-1))\n","                i += 1\n","            probas = torch.cat(probas, dim=1)\n","            \n","            return torch.cat(predicts, dim=1)"],"metadata":{"id":"uPJauY4hAqJ6","executionInfo":{"status":"ok","timestamp":1666285910331,"user_tz":-180,"elapsed":2,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class DateNormalizer(nn.Module):\n","    def __init__(self, input_vocab_len, target_vocab_len, \n","                 emb__dim, hidden_dim, eos_id):\n","        super().__init__()\n","        self.encoder = Encoder(input_vocab_len, emb_dim, hidden_dim)\n","        self.decoder = Decoder(target_vocab_len, emb_dim, hidden_dim, eos_id)\n","\n","    def forward(self, x, target_sequence):\n","        context = self.encoder(x)\n","        pred = self.decoder(context, target_sequence)\n","\n","        return pred"],"metadata":{"id":"KTz2txO4LTZ3","executionInfo":{"status":"ok","timestamp":1666285918490,"user_tz":-180,"elapsed":14,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WBFZc1qY6HsC","executionInfo":{"status":"ok","timestamp":1666285796391,"user_tz":-180,"elapsed":1651,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#hyper params\n","input_vocab_size = len(dataset.input_sequnces_vocab)\n","target_vocab_size = len(dataset.output_sequnces_vocab)\n","eos_id = dataset.output_sequnces_vocab['#']\n","#TODO try to use other model parameters\n","emb_dim = 128\n","hidden = 256\n","n_epochs = 10\n","batch_size = 64\n","cuda_device = -1\n","batch_size = 100\n","device = f'cuda:{cuda_device}' if cuda_device != -1 else 'cpu'"],"metadata":{"id":"K_PACmDaH8Z7","executionInfo":{"status":"ok","timestamp":1666285796391,"user_tz":-180,"elapsed":10,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["model = DateNormalizer(input_vocab_size, target_vocab_size, emb_dim, hidden, eos_id)\n","model.train()\n","optim = torch.optim.Adam(model.parameters(), lr=0.001)\n","loss_func = nn.CrossEntropyLoss()"],"metadata":{"id":"a4gX5zVDIZdu","executionInfo":{"status":"ok","timestamp":1666285919943,"user_tz":-180,"elapsed":3,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jVX0P0otIk4D","executionInfo":{"status":"ok","timestamp":1666285796392,"user_tz":-180,"elapsed":10,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9bMsBeqV8GCf","executionInfo":{"status":"ok","timestamp":1666285796393,"user_tz":-180,"elapsed":10,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["\n","for epoch in range(n_epochs):\n","    dataloader = DataLoader(dataset, \n","                            batch_size, \n","                            shuffle=True, \n","                            collate_fn=collate_fn,\n","                            drop_last = True,\n","                            )\n","    for i, batch in enumerate(dataloader):\n","        optim.zero_grad()\n","        target = batch['target'].to(device)\n","        predicts = model(batch['data'].to(device), target[:, :-1])\n","        loss = loss_func(predicts.reshape(-1, target_vocab_size), \n","                         target[:, 1:].reshape(-1))\n","        \n","        loss.backward()\n","        optim.step()\n","        if i % 100 == 0:\n","            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n","    test = '14 мая 1978'\n","    test_encoded = torch.tensor([[dataset.input_sequnces_vocab[c] for c in test]])\n","    test_encoded = test_encoded.to(device)\n","    bos_input = torch.tensor([[dataset.output_sequnces_vocab['~']]]).to(device)\n","    with torch.no_grad():\n","        model.eval()\n","        test_pred = model(test_encoded, bos_input)\n","        model.train()\n","    decode = list(dataset.output_sequnces_vocab.keys())\n","    out_str = ''\n","    for i in test_pred.squeeze().cpu().detach().tolist():\n","        out_str += decode[i]\n","    print(out_str)\n","\n","    torch.save(model.state_dict(), f'./seq2seq_chkpt_{epoch}.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r2f3MATJ8GKb","executionInfo":{"status":"ok","timestamp":1666286008088,"user_tz":-180,"elapsed":83314,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}},"outputId":"9553e406-3777-43aa-a8ab-6da743bd555f"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 0, step: 0, loss: 2.714406728744507\n","1998-02-12\n","#\n","epoch: 1, step: 0, loss: 0.8631631731987\n","1974-01-14\n","#\n","epoch: 2, step: 0, loss: 0.7566551566123962\n","1977-07-19\n","#\n","epoch: 3, step: 0, loss: 0.6143466830253601\n","1978-01-03\n","#\n","epoch: 4, step: 0, loss: 0.5181354284286499\n","1978-04-03\n","#\n","epoch: 5, step: 0, loss: 0.45870569348335266\n","1978-04-18\n","#\n","epoch: 6, step: 0, loss: 0.3724606931209564\n","1978-03-13\n","#\n","epoch: 7, step: 0, loss: 0.3008843660354614\n","1978-03-19\n","#\n","epoch: 8, step: 0, loss: 0.26437878608703613\n","1978-03-16\n","#\n","epoch: 9, step: 0, loss: 0.20521339774131775\n","1978-05-14\n","#\n"]}]},{"cell_type":"code","source":["dataset.output_sequnces_vocab"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FX_HfQr6Zzra","executionInfo":{"status":"ok","timestamp":1666286316886,"user_tz":-180,"elapsed":438,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}},"outputId":"cd2a8638-27af-40d6-e321-a3af2f8c0358"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'pad': 0,\n"," '~': 1,\n"," '#': 2,\n"," '1': 3,\n"," '9': 4,\n"," '8': 5,\n"," '-': 6,\n"," '0': 7,\n"," '5': 8,\n"," '\\n': 9,\n"," '2': 10,\n"," '7': 11,\n"," '4': 12,\n"," '6': 13,\n"," '3': 14}"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":[],"metadata":{"id":"soes4kIU8FDq","executionInfo":{"status":"aborted","timestamp":1666285804161,"user_tz":-180,"elapsed":10,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9PbgCjN48FRe","executionInfo":{"status":"aborted","timestamp":1666285804162,"user_tz":-180,"elapsed":11,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"74gggSX58Fe9","executionInfo":{"status":"aborted","timestamp":1666285804163,"user_tz":-180,"elapsed":12,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"-57Jq-CW8NmD"}}]}