{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOuNPSzkU2RvDhnfGIfG3pz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"in0PyicHhZDG","executionInfo":{"status":"ok","timestamp":1666287808602,"user_tz":-180,"elapsed":1491,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"outputs":[],"source":["import datetime\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"73ieMA485Tme","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666287829174,"user_tz":-180,"elapsed":20576,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}},"outputId":"838e4673-a1a1-4275-a4db-7b3beb6f2dc3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["fn = 'drive/My Drive/dataset_text.txt'\n"],"metadata":{"id":"Os4tVkvmkTIp","executionInfo":{"status":"ok","timestamp":1666287829175,"user_tz":-180,"elapsed":9,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset\n","from torch.nn.utils.rnn import pad_sequence\n","\n","\n","class DatasetSeq2Seq(Dataset):\n","    def __init__(self, file_name, train_lang='en', bos: str = '~', eos: str = '#'):\n","\n","        with open(file_name, 'r') as f:\n","            train = f.readlines()\n","\n","        self.input_sequnces_vocab = {'pad': 0, bos: 1, eos: 2}\n","        self.output_sequnces_vocab = {'pad': 0, bos: 1, eos: 2}\n","\n","        self.input_sequnces = []\n","        self.output_sequnces = []\n","\n","        n_input = 3\n","        n_output = 3\n","        for line in train:\n","            split_line = line.split('\\t')\n","\n","            sequence = [self.input_sequnces_vocab[bos]]\n","\n","            for char in split_line[0].strip():\n","                if self.input_sequnces_vocab.get(char) is None:\n","                    self.input_sequnces_vocab[char] = n_input\n","                    n_input += 1\n","                sequence.append(self.input_sequnces_vocab[char])\n","            sequence.append(self.input_sequnces_vocab[eos])\n","\n","            target = [self.output_sequnces_vocab[bos]]\n","            for char in split_line[2].strip():\n","                if self.output_sequnces_vocab.get(char) is None:\n","                    self.output_sequnces_vocab[char] = n_output\n","                    n_output += 1\n","                target.append(self.output_sequnces_vocab[char])\n","            target.append(self.output_sequnces_vocab[eos])\n","\n","            self.input_sequnces.append(sequence)\n","            self.output_sequnces.append(target)\n","\n","        self.target_decode = [k for k in self.output_sequnces_vocab.keys()]\n","\n","    def __len__(self):\n","        return len(self.input_sequnces)\n","\n","    def __getitem__(self, index):\n","        return {\n","            'data': self.input_sequnces[index],\n","            'target': self.output_sequnces[index],\n","        }\n","\n","\n","def collate_fn(input_data):\n","    data = []\n","    targets = []\n","\n","    for item in input_data:\n","        data.append(torch.as_tensor(item['data']))\n","        targets.append(torch.as_tensor(item['target']))\n","\n","    data = pad_sequence(data, batch_first=True, padding_value=0)\n","    targets = pad_sequence(targets, batch_first=True, padding_value=0)\n","    data_mask = data > 0\n","    targets_mask = targets > 0\n","\n","    return {'data': data, \n","            'target': targets, \n","            'data_mask': data_mask, \n","            'targets_mask': targets_mask,\n","            }"],"metadata":{"id":"SI8UCZuy7hTK","executionInfo":{"status":"ok","timestamp":1666287829175,"user_tz":-180,"elapsed":8,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["dataset = DatasetSeq2Seq(fn)"],"metadata":{"id":"dhJuBtoz7f43","executionInfo":{"status":"ok","timestamp":1666287829176,"user_tz":-180,"elapsed":8,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#padding\n","# seq1 = [1, 2, 3, 4]\n","# seq2 = [9, 7, 6, 4, 3, 7, 5]\n","# pad seq1 equal seq2\n","# seq1 = [1, 2, 3, 4, 0, 0, 0]\n","# concat(seq1, seq2) [[1, 2, 3, 4, 0, 0, 0],\n","#                     [9, 7, 6, 4, 3, 7, 5]]"],"metadata":{"id":"0zXXXYP37gFL","executionInfo":{"status":"ok","timestamp":1666287829176,"user_tz":-180,"elapsed":8,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","\n","\n","class ScaledDotProductAttention(nn.Module):\n","    ''' Scaled Dot-Product Attention '''\n","\n","    def __init__(self, temperature=1, attn_dropout=0.1):\n","        super().__init__()\n","        self.temperature = temperature\n","        self.dropout = nn.Dropout(attn_dropout)\n","        self.softmax = nn.Softmax(dim=2)\n","\n","    def forward(self, q, k, v, mask=None):\n","\n","        attn = torch.bmm(q, # B x T1 x V\n","                         k.transpose(1, 2), # B x T2 x V -> B x V x T2\n","                         ) # B x T1 x T2\n","        attn = attn / self.temperature\n","\n","        if mask is not None:\n","            attn = attn.masked_fill(~mask, -np.inf)\n","\n","        attn = self.softmax(attn)\n","\n","        if mask is not None:\n","            attn = attn.masked_fill(~mask, 0.)\n","\n","        attn = self.dropout(attn)\n","        output = torch.bmm(attn, v) # B x T1 x T2 @ B x T1 x V\n","\n","        return output, attn"],"metadata":{"id":"eGc_VBoscT2C","executionInfo":{"status":"ok","timestamp":1666287829176,"user_tz":-180,"elapsed":7,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__(self, vocab_len, emb_dim, hidden_dim):\n","        super().__init__()\n","        self.emb = nn.Embedding(vocab_len, emb_dim)\n","        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n","\n","    def forward(self, x):\n","        emb = self.emb(x)\n","        encoded_sequence, context = self.rnn(emb)\n","\n","        return context, encoded_sequence\n","\n","class Decoder(nn.Module):\n","    def __init__(self, vocab_len, emb_dim, hidden_dim, eos_id):\n","        super().__init__()\n","        self.emb = nn.Embedding(vocab_len, emb_dim)\n","        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n","        self.classifier = nn.Linear(2*hidden_dim, vocab_len)\n","        self.do = nn.Dropout(0.2)\n","        self.eos = eos_id\n","        self.attention = ScaledDotProductAttention()\n","\n","    def forward(self, context, target_sequence, encoded_sequence):\n","        if self.training:\n","            emb = self.emb(target_sequence)\n","            all_hid, _ = self.rnn(emb, context)\n","            attn_res, attn_mtx = self.attention(all_hid, \n","                                                encoded_sequence, \n","                                                encoded_sequence)\n","            clf_inp = torch.cat((attn_res, all_hid), dim=-1)\n","            pred_cls = self.classifier(self.do(clf_inp))\n","\n","            return pred_cls\n","        else:\n","            predicts = []\n","            probas = []\n","            predicted_token = target_sequence #on this step target sequence contains bos only\n","            i = 0\n","            while predicted_token.item() != self.eos and i < 20:\n","                emb = self.emb(predicted_token)\n","                context, _ = self.rnn(emb, context) # context B x 1 x Hid\n","                attn_res, attn_mtx = self.attention(context, \n","                                                    encoded_sequence, \n","                                                    encoded_sequence)\n","                clf_inp = torch.cat((attn_res, context), dim=-1)\n","                pred = self.classifier(self.do(clf_inp))\n","                predicted_token = torch.argmax(pred, dim=-1) # B x 1\n","                predicts.append(predicted_token)\n","                probas.append(torch.softmax(pred, dim=-1))\n","                i += 1\n","            probas = torch.cat(probas, dim=1)\n","            \n","            return torch.cat(predicts, dim=1)"],"metadata":{"id":"uPJauY4hAqJ6","executionInfo":{"status":"ok","timestamp":1666288349322,"user_tz":-180,"elapsed":3,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["class DateNormalizer(nn.Module):\n","    def __init__(self, input_vocab_len, target_vocab_len, \n","                 emb__dim, hidden_dim, eos_id):\n","        super().__init__()\n","        self.encoder = Encoder(input_vocab_len, emb_dim, hidden_dim)\n","        self.decoder = Decoder(target_vocab_len, emb_dim, hidden_dim, eos_id)\n","\n","    def forward(self, x, target_sequence):\n","        context, encoded_sequece = self.encoder(x)\n","        pred = self.decoder(context, target_sequence, encoded_sequece)\n","\n","        return pred"],"metadata":{"id":"KTz2txO4LTZ3","executionInfo":{"status":"ok","timestamp":1666288353499,"user_tz":-180,"elapsed":511,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WBFZc1qY6HsC","executionInfo":{"status":"ok","timestamp":1666287829178,"user_tz":-180,"elapsed":8,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#hyper params\n","input_vocab_size = len(dataset.input_sequnces_vocab)\n","target_vocab_size = len(dataset.output_sequnces_vocab)\n","eos_id = dataset.output_sequnces_vocab['#']\n","#TODO try to use other model parameters\n","emb_dim = 128\n","hidden = 256\n","n_epochs = 20\n","batch_size = 128\n","cuda_device = -1\n","batch_size = 100\n","device = f'cuda:{cuda_device}' if cuda_device != -1 else 'cpu'"],"metadata":{"id":"K_PACmDaH8Z7","executionInfo":{"status":"ok","timestamp":1666288353500,"user_tz":-180,"elapsed":3,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["model = DateNormalizer(input_vocab_size, target_vocab_size, emb_dim, hidden, eos_id)\n","model.train()\n","optim = torch.optim.Adam(model.parameters(), lr=0.001)\n","loss_func = nn.CrossEntropyLoss()"],"metadata":{"id":"a4gX5zVDIZdu","executionInfo":{"status":"ok","timestamp":1666288356855,"user_tz":-180,"elapsed":2,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jVX0P0otIk4D","executionInfo":{"status":"ok","timestamp":1666287829600,"user_tz":-180,"elapsed":6,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9bMsBeqV8GCf","executionInfo":{"status":"ok","timestamp":1666287829600,"user_tz":-180,"elapsed":5,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["\n","for epoch in range(n_epochs):\n","    dataloader = DataLoader(dataset, \n","                            batch_size, \n","                            shuffle=True, \n","                            collate_fn=collate_fn,\n","                            drop_last = True,\n","                            )\n","    for i, batch in enumerate(dataloader):\n","        optim.zero_grad()\n","        target = batch['target'].to(device)\n","        predicts = model(batch['data'].to(device), target[:, :-1])\n","        loss = loss_func(predicts.reshape(-1, target_vocab_size), \n","                         target[:, 1:].reshape(-1))\n","        \n","        loss.backward()\n","        optim.step()\n","        if i % 10 == 0:\n","            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n","    test = '14 мая 1978'\n","    test_encoded = torch.tensor([[dataset.input_sequnces_vocab[c] for c in test]])\n","    test_encoded = test_encoded.to(device)\n","    bos_input = torch.tensor([[dataset.output_sequnces_vocab['~']]]).to(device)\n","    with torch.no_grad():\n","        model.eval()\n","        test_pred = model(test_encoded, bos_input)\n","        model.train()\n","    decode = list(dataset.output_sequnces_vocab.keys())\n","    out_str = ''\n","    for i in test_pred.squeeze().cpu().detach().tolist():\n","        out_str += decode[i]\n","    print(out_str)\n","\n","    torch.save(model.state_dict(), f'./seq2seq_chkpt_{epoch}.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"r2f3MATJ8GKb","executionInfo":{"status":"error","timestamp":1666288482316,"user_tz":-180,"elapsed":123040,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}},"outputId":"9c894880-0352-4d4e-d5b8-0bf2e9602b04"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 0, step: 0, loss: 2.629819631576538\n","epoch: 0, step: 10, loss: 1.638836145401001\n","epoch: 0, step: 20, loss: 1.301824688911438\n","epoch: 0, step: 30, loss: 1.0219420194625854\n","epoch: 0, step: 40, loss: 0.8506795763969421\n","88-05-3#\n","epoch: 1, step: 0, loss: 0.6761842370033264\n","epoch: 1, step: 10, loss: 0.5632002949714661\n","epoch: 1, step: 20, loss: 0.465453565120697\n","epoch: 1, step: 30, loss: 0.4317287504673004\n","epoch: 1, step: 40, loss: 0.43588560819625854\n","888-55-44#\n","epoch: 2, step: 0, loss: 0.39425450563430786\n","epoch: 2, step: 10, loss: 0.3523031771183014\n","epoch: 2, step: 20, loss: 0.2975306510925293\n","epoch: 2, step: 30, loss: 0.29724907875061035\n","epoch: 2, step: 40, loss: 0.3182416260242462\n","888-55-44#\n","epoch: 3, step: 0, loss: 0.33475661277770996\n","epoch: 3, step: 10, loss: 0.3043808937072754\n","epoch: 3, step: 20, loss: 0.2866644859313965\n","epoch: 3, step: 30, loss: 0.263384073972702\n","epoch: 3, step: 40, loss: 0.2779485881328583\n","888-55-44#\n","epoch: 4, step: 0, loss: 0.23140473663806915\n","epoch: 4, step: 10, loss: 0.2486434429883957\n","epoch: 4, step: 20, loss: 0.2594922184944153\n","epoch: 4, step: 30, loss: 0.2014208436012268\n","epoch: 4, step: 40, loss: 0.23171214759349823\n","889-55-44#\n","epoch: 5, step: 0, loss: 0.17654690146446228\n","epoch: 5, step: 10, loss: 0.2012903243303299\n","epoch: 5, step: 20, loss: 0.18065352737903595\n","epoch: 5, step: 30, loss: 0.1655871421098709\n","epoch: 5, step: 40, loss: 0.16414712369441986\n","888-55-44#\n","epoch: 6, step: 0, loss: 0.16659533977508545\n","epoch: 6, step: 10, loss: 0.15468595921993256\n","epoch: 6, step: 20, loss: 0.13759471476078033\n","epoch: 6, step: 30, loss: 0.1385505199432373\n","epoch: 6, step: 40, loss: 0.1556929051876068\n","888-55-44#\n","epoch: 7, step: 0, loss: 0.131626695394516\n","epoch: 7, step: 10, loss: 0.1287304162979126\n","epoch: 7, step: 20, loss: 0.13949409127235413\n","epoch: 7, step: 30, loss: 0.10100430995225906\n","epoch: 7, step: 40, loss: 0.10139734297990799\n","888-53-44#\n","epoch: 8, step: 0, loss: 0.10177625715732574\n","epoch: 8, step: 10, loss: 0.09473160654306412\n","epoch: 8, step: 20, loss: 0.09700850397348404\n","epoch: 8, step: 30, loss: 0.08781998604536057\n","epoch: 8, step: 40, loss: 0.12760718166828156\n","88-55-44#\n","epoch: 9, step: 0, loss: 0.11146986484527588\n","epoch: 9, step: 10, loss: 0.09701693803071976\n","epoch: 9, step: 20, loss: 0.08760124444961548\n","epoch: 9, step: 30, loss: 0.09444354474544525\n","epoch: 9, step: 40, loss: 0.12233875691890717\n","88-55-44#\n","epoch: 10, step: 0, loss: 0.11733885109424591\n","epoch: 10, step: 10, loss: 0.09840605407953262\n","epoch: 10, step: 20, loss: 0.08404025435447693\n","epoch: 10, step: 30, loss: 0.07725314795970917\n","epoch: 10, step: 40, loss: 0.07758840173482895\n","88-55-44#\n","epoch: 11, step: 0, loss: 0.07313733547925949\n","epoch: 11, step: 10, loss: 0.0777125284075737\n","epoch: 11, step: 20, loss: 0.1495373547077179\n","epoch: 11, step: 30, loss: 0.09637624770402908\n","epoch: 11, step: 40, loss: 0.08968660235404968\n","88-55-44#\n","epoch: 12, step: 0, loss: 0.09072273224592209\n","epoch: 12, step: 10, loss: 0.08062120527029037\n","epoch: 12, step: 20, loss: 0.08120753616094589\n","epoch: 12, step: 30, loss: 0.09198938310146332\n","epoch: 12, step: 40, loss: 0.09322939068078995\n","88-55-44#\n","epoch: 13, step: 0, loss: 0.05052991583943367\n","epoch: 13, step: 10, loss: 0.0717068612575531\n","epoch: 13, step: 20, loss: 0.0641016960144043\n","epoch: 13, step: 30, loss: 0.05768607184290886\n","epoch: 13, step: 40, loss: 0.04809131845831871\n","88-55-44#\n","epoch: 14, step: 0, loss: 0.06440183520317078\n","epoch: 14, step: 10, loss: 0.06928832083940506\n","epoch: 14, step: 20, loss: 0.07723823934793472\n","epoch: 14, step: 30, loss: 0.06551845371723175\n","epoch: 14, step: 40, loss: 0.07988366484642029\n","88-55-44#\n","epoch: 15, step: 0, loss: 0.06126469001173973\n","epoch: 15, step: 10, loss: 0.07700707018375397\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-f8eaa64ec2a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                          target[:, 1:].reshape(-1))\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["test_pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FX_HfQr6Zzra","executionInfo":{"status":"ok","timestamp":1666287991428,"user_tz":-180,"elapsed":3,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}},"outputId":"15e05610-f26c-486a-f1da-196e61df98cb"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[2]])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":[],"metadata":{"id":"soes4kIU8FDq","executionInfo":{"status":"ok","timestamp":1666287904983,"user_tz":-180,"elapsed":16,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9PbgCjN48FRe","executionInfo":{"status":"ok","timestamp":1666287904986,"user_tz":-180,"elapsed":19,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"74gggSX58Fe9","executionInfo":{"status":"ok","timestamp":1666287904987,"user_tz":-180,"elapsed":19,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"-57Jq-CW8NmD"}}]}